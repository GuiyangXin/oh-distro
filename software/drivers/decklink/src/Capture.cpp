/* -LICENSE-START-
** Copyright (c) 2013 Blackmagic Design
**
** Permission is hereby granted, free of charge, to any person or organization
** obtaining a copy of the software and accompanying documentation covered by
** this license (the "Software") to use, reproduce, display, distribute,
** execute, and transmit the Software, and to prepare derivative works of the
** Software, and to permit third-parties to whom the Software is furnished to
** do so, all subject to the following:
**
** The copyright notices in the Software and this entire statement, including
** the above license grant, this restriction and the following disclaimer,
** must be included in all copies of the Software, in whole or in part, and
** all derivative works of the Software, unless such copies or derivative
** works are solely in the form of machine-executable object code generated by
** a source language processor.
**
** THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
** IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
** FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
** SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
** FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
** ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
** DEALINGS IN THE SOFTWARE.
** -LICENSE-END-
*/

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <pthread.h>
#include <unistd.h>
#include <fcntl.h>
#include <csignal>

#include "DeckLinkAPI.h"
#include "Capture.h"
#include "Config.h"

#include <lcmtypes/bot_core/image_t.hpp>
#include <lcm/lcm-cpp.hpp>
#include <bot_core/timestamp.h>
#include <jpeg-utils/jpeg-utils.h>
#include <boost/thread/thread.hpp>
#include <boost/shared_ptr.hpp>
#include <queue>

static pthread_mutex_t	g_sleepMutex;
static pthread_cond_t	g_sleepCond;
static int				g_videoOutputFile = -1;
static int				g_audioOutputFile = -1;
static bool				g_do_exit = false;

static BMDConfig		g_config;

static IDeckLinkInput*	g_deckLinkInput = NULL;

static IDeckLinkOutput* g_deckLinkOutput = NULL;

static lcm::LCM* g_lcm = NULL;

static IDeckLinkVideoConversion* conversionInst = NULL;

static unsigned long	g_frameCount = 0;

DeckLinkCaptureDelegate::DeckLinkCaptureDelegate() : m_refCount(0)
{
	pthread_mutex_init(&m_mutex, NULL);
}

DeckLinkCaptureDelegate::~DeckLinkCaptureDelegate()
{
	pthread_mutex_destroy(&m_mutex);
}

ULONG DeckLinkCaptureDelegate::AddRef(void)
{
	pthread_mutex_lock(&m_mutex);
		m_refCount++;
	pthread_mutex_unlock(&m_mutex);

	return (ULONG)m_refCount;
}

ULONG DeckLinkCaptureDelegate::Release(void)
{
	pthread_mutex_lock(&m_mutex);
		m_refCount--;
	pthread_mutex_unlock(&m_mutex);

	if (m_refCount == 0)
	{
		delete this;
		return 0;
	}

	return (ULONG)m_refCount;
}


//----------------------------------------------------------------------------
namespace
{

template<typename T>
class SynchronizedQueue
{
  public:

    SynchronizedQueue () :
      queue_(), mutex_(), cond_(), request_to_end_(false), enqueue_data_(true) { }

    void
    enqueue (const T& data)
    {
      boost::unique_lock<boost::mutex> lock (mutex_);

      if (enqueue_data_)
      {
        queue_.push (data);
        cond_.notify_one ();
      }
    }

    bool
    dequeue (T& result)
    {
      boost::unique_lock<boost::mutex> lock (mutex_);

      while (queue_.empty () && (!request_to_end_))
      {
        cond_.wait (lock);
      }

      if (request_to_end_)
      {
        doEndActions ();
        return false;
      }

      result = queue_.front ();
      queue_.pop ();

      return true;
    }

    void
    stopQueue ()
    {
      boost::unique_lock<boost::mutex> lock (mutex_);
      request_to_end_ = true;
      cond_.notify_one ();
    }

    unsigned int
    size ()
    {
      boost::unique_lock<boost::mutex> lock (mutex_);
      return static_cast<unsigned int> (queue_.size ());
    }

    bool
    isEmpty () const
    {
      boost::unique_lock<boost::mutex> lock (mutex_);
      return (queue_.empty ());
    }

  private:
    void
    doEndActions ()
    {
      enqueue_data_ = false;

      while (!queue_.empty ())
      {
        queue_.pop ();
      }
    }

    std::queue<T> queue_;              // Use STL queue to store data
    mutable boost::mutex mutex_;       // The mutex to synchronise on
    boost::condition_variable cond_;   // The condition to wait for

    bool request_to_end_;
    bool enqueue_data_;
};

void convert(IDeckLinkMutableVideoFrame* videoFrame, bot_core::image_t& oImage) {

  oImage.width = videoFrame->GetWidth();
  oImage.height = videoFrame->GetHeight();
  oImage.row_stride = videoFrame->GetRowBytes();
  oImage.size = oImage.height*oImage.row_stride;
  oImage.nmetadata = 0;

  //printf("frame: %d x %d  (%d row bytes)\n", oImage.width, oImage.height, oImage.row_stride);

  // compress if necessary
  uint8_t* data = 0;
  videoFrame->GetBytes((void**)&data);


  bool shouldCompress = true;

  if (shouldCompress) {

    //double oldMB = oImage.size / (1024.0*1024.0);

    int compressionQuality = g_config.m_compressionQuality;
    std::vector<uint8_t> dest(oImage.size);
    jpeg_compress_8u_bgra(data, oImage.width, oImage.height, oImage.row_stride,
                         dest.data(), &oImage.size, compressionQuality);
    oImage.pixelformat = bot_core::image_t::PIXEL_FORMAT_MJPEG;
    oImage.data.resize(oImage.size);
    std::copy(dest.data(), dest.data()+oImage.size, oImage.data.begin());

    //double newMB = oImage.size / (1024.0*1024.0);
    //printf("compression %.2f --> %.2f MB\n", oldMB, newMB);
  }

  // otherwise just set raw bytes
  else {

    oImage.pixelformat = bot_core::image_t::PIXEL_FORMAT_BGRA;
    oImage.data.resize(oImage.size);
    std::copy(data, data + oImage.size, oImage.data.begin());
  }
}

class FrameData
{
public:
  FrameData()
  {
    timestamp = 0;
    outputFrame = NULL;
  }

  FrameData(IDeckLinkMutableVideoFrame* frame, int64_t t) : timestamp(t), outputFrame(frame)
  {
  }
  int64_t timestamp;
  IDeckLinkMutableVideoFrame* outputFrame;
};


class FrameConsumer
{
public:

  FrameConsumer()
  {
  }

  void Start()
  {
    this->Thread = boost::shared_ptr<boost::thread>(
      new boost::thread(boost::bind(&FrameConsumer::ThreadLoop, this)));

    this->Thread2 = boost::shared_ptr<boost::thread>(
      new boost::thread(boost::bind(&FrameConsumer::ThreadLoop, this)));
  }

  void Stop()
  {
    this->Queue.stopQueue();
  }

  void ThreadLoop()
  {
    FrameData frameData;

    while (this->Queue.dequeue(frameData))
    {
      bot_core::image_t msg;
      msg.utime = frameData.timestamp;

      double latencyWarningTime = 0.25;
      double latencyTime = (bot_timestamp_now() - frameData.timestamp)*1e-6;
      if (latencyTime > latencyWarningTime)
      {
        printf("%.3f seconds behind.  %u frames in queue\n", latencyTime, this->Queue.size());
      }
      convert(frameData.outputFrame, msg);
      g_lcm->publish(g_config.m_lcmChannelName, &msg);
      frameData.outputFrame->Release();
    }
  }

  SynchronizedQueue<FrameData> Queue;
  boost::shared_ptr<boost::thread> Thread;
  boost::shared_ptr<boost::thread> Thread2;
};


FrameConsumer frameConsumer;

}


HRESULT DeckLinkCaptureDelegate::VideoInputFrameArrived(IDeckLinkVideoInputFrame* videoFrame, IDeckLinkAudioInputPacket* audioFrame)
{
	IDeckLinkVideoFrame*				rightEyeFrame = NULL;
	IDeckLinkVideoFrame3DExtensions*	threeDExtensions = NULL;
	void*								frameBytes;
	void*								audioFrameBytes;

	// Handle Video Frame
	if (videoFrame)
	{
		// If 3D mode is enabled we retreive the 3D extensions interface which gives.
		// us access to the right eye frame by calling GetFrameForRightEye() .
		if ( (videoFrame->QueryInterface(IID_IDeckLinkVideoFrame3DExtensions, (void **) &threeDExtensions) != S_OK) ||
			(threeDExtensions->GetFrameForRightEye(&rightEyeFrame) != S_OK))
		{
			rightEyeFrame = NULL;
		}

		if (threeDExtensions)
			threeDExtensions->Release();

		if (videoFrame->GetFlags() & bmdFrameHasNoInputSource)
		{
			printf("Frame received (#%lu) - No input signal detected\n", g_frameCount);
		}
		else
		{
			const char *timecodeString = NULL;
			if (g_config.m_timecodeFormat != 0)
			{
				IDeckLinkTimecode *timecode;
				if (videoFrame->GetTimecode(g_config.m_timecodeFormat, &timecode) == S_OK)
				{
					timecode->GetString(&timecodeString);
				}
			}

			//printf("Frame received (#%lu) [%s] - %s - Size: %li bytes\n",
			//	g_frameCount,
			//	timecodeString != NULL ? timecodeString : "No timecode",
			//	rightEyeFrame != NULL ? "Valid Frame (3D left/right)" : "Valid Frame",
			//	videoFrame->GetRowBytes() * videoFrame->GetHeight());

      int64_t timestampNow = bot_timestamp_now();

      if (g_config.m_lcmChannelName)
      {
        IDeckLinkMutableVideoFrame* outputFrame;
        g_deckLinkOutput->CreateVideoFrame(videoFrame->GetWidth(), videoFrame->GetHeight(), videoFrame->GetWidth()*4, bmdFormat8BitBGRA, bmdFrameFlagDefault, &outputFrame);
        HRESULT convertResult = conversionInst->ConvertFrame(videoFrame, outputFrame);

        frameConsumer.Queue.enqueue(FrameData(outputFrame, timestampNow));
      }

      static int64_t baseTime = timestampNow;
      static uint64_t frameCount = g_frameCount;
      double elapsedTime = (timestampNow - baseTime) * 1e-6;
      if (elapsedTime > 1.0)
      {
        printf("capturing at %.2f fps.\n", (g_frameCount - frameCount)/elapsedTime);
        baseTime = timestampNow;
        frameCount = g_frameCount;
      }

			if (timecodeString)
				free((void*)timecodeString);

			if (g_videoOutputFile != -1)
			{
				videoFrame->GetBytes(&frameBytes);
				write(g_videoOutputFile, frameBytes, videoFrame->GetRowBytes() * videoFrame->GetHeight());

				if (rightEyeFrame)
				{
					rightEyeFrame->GetBytes(&frameBytes);
					write(g_videoOutputFile, frameBytes, videoFrame->GetRowBytes() * videoFrame->GetHeight());
				}
			}
		}

		if (rightEyeFrame)
			rightEyeFrame->Release();

		g_frameCount++;
	}

	// Handle Audio Frame
	if (audioFrame)
	{
		if (g_audioOutputFile != -1)
		{
			audioFrame->GetBytes(&audioFrameBytes);
			write(g_audioOutputFile, audioFrameBytes, audioFrame->GetSampleFrameCount() * g_config.m_audioChannels * (g_config.m_audioSampleDepth / 8));
		}
	}

	if (g_config.m_maxFrames > 0 && videoFrame && g_frameCount >= g_config.m_maxFrames)
	{
		g_do_exit = true;
		pthread_cond_signal(&g_sleepCond);
	}

	return S_OK;
}

HRESULT DeckLinkCaptureDelegate::VideoInputFormatChanged(BMDVideoInputFormatChangedEvents events, IDeckLinkDisplayMode *mode, BMDDetectedVideoInputFormatFlags)
{
	// This only gets called if bmdVideoInputEnableFormatDetection was set
	// when enabling video input
	HRESULT	result;
	char*	displayModeName = NULL;

	if (!(events & bmdVideoInputDisplayModeChanged))
		return S_OK;

	mode->GetName((const char**)&displayModeName);
	printf("Video format changed to %s\n", displayModeName);

	if (displayModeName)
		free(displayModeName);

	if (g_deckLinkInput)
	{
		g_deckLinkInput->StopStreams();

		result = g_deckLinkInput->EnableVideoInput(mode->GetDisplayMode(), g_config.m_pixelFormat, g_config.m_inputFlags);
		if (result != S_OK)
		{
			fprintf(stderr, "Failed to switch video mode\n");
			goto bail;
		}

		g_deckLinkInput->StartStreams();
	}

bail:
	return S_OK;
}

static void sigfunc(int signum)
{
	if (signum == SIGINT || signum == SIGTERM)
		g_do_exit = true;

	pthread_cond_signal(&g_sleepCond);
}

int main(int argc, char *argv[])
{
	HRESULT							result;
	int								exitStatus = 1;
	int								idx;

	IDeckLinkIterator*				deckLinkIterator = NULL;
	IDeckLink*						deckLink = NULL;

	IDeckLinkAttributes*			deckLinkAttributes = NULL;
	bool							formatDetectionSupported;

	IDeckLinkDisplayModeIterator*	displayModeIterator = NULL;
	IDeckLinkDisplayMode*			displayMode = NULL;
	char*							displayModeName = NULL;
	BMDDisplayModeSupport			displayModeSupported;

	DeckLinkCaptureDelegate*		delegate = NULL;

	pthread_mutex_init(&g_sleepMutex, NULL);
	pthread_cond_init(&g_sleepCond, NULL);

	signal(SIGINT, sigfunc);
	signal(SIGTERM, sigfunc);
	signal(SIGHUP, sigfunc);

	// Process the command line arguments
	if (!g_config.ParseArguments(argc, argv))
	{
		g_config.DisplayUsage(exitStatus);
		goto bail;
	}

  g_lcm = new lcm::LCM();
  conversionInst = CreateVideoConversionInstance();

	// Get the DeckLink device
	deckLinkIterator = CreateDeckLinkIteratorInstance();
	if (!deckLinkIterator)
	{
		fprintf(stderr, "This application requires the DeckLink drivers installed.\n");
		goto bail;
	}

	idx = g_config.m_deckLinkIndex;

	while ((result = deckLinkIterator->Next(&deckLink)) == S_OK)
	{
		if (idx == 0)
			break;
		--idx;

		deckLink->Release();
	}

	if (result != S_OK || deckLink == NULL)
	{
		fprintf(stderr, "Unable to get DeckLink device %u\n", g_config.m_deckLinkIndex);
		goto bail;
	}

	// Get the input (capture) interface of the DeckLink device
	result = deckLink->QueryInterface(IID_IDeckLinkInput, (void**)&g_deckLinkInput);
	if (result != S_OK)
		goto bail;



	// Get the output (display) interface of the DeckLink device
	if (deckLink->QueryInterface(IID_IDeckLinkOutput, (void**)&g_deckLinkOutput) != S_OK)
		goto bail;


	// Get the display mode
	if (g_config.m_displayModeIndex == -1)
	{
		// Check the card supports format detection
		result = deckLink->QueryInterface(IID_IDeckLinkAttributes, (void**)&deckLinkAttributes);
		if (result == S_OK)
		{
			result = deckLinkAttributes->GetFlag(BMDDeckLinkSupportsInputFormatDetection, &formatDetectionSupported);
			if (result != S_OK || !formatDetectionSupported)
			{
				fprintf(stderr, "Format detection is not supported on this device\n");
				goto bail;
			}
		}

		g_config.m_inputFlags |= bmdVideoInputEnableFormatDetection;

		// Format detection still needs a valid mode to start with
		idx = 0;
	}
	else
	{
		idx = g_config.m_displayModeIndex;
	}

	result = g_deckLinkInput->GetDisplayModeIterator(&displayModeIterator);
	if (result != S_OK)
		goto bail;

	while ((result = displayModeIterator->Next(&displayMode)) == S_OK)
	{
		if (idx == 0)
			break;
		--idx;

		displayMode->Release();
	}

	if (result != S_OK || displayMode == NULL)
	{
		fprintf(stderr, "Unable to get display mode %d\n", g_config.m_displayModeIndex);
		goto bail;
	}

	// Get display mode name
	result = displayMode->GetName((const char**)&displayModeName);
	if (result != S_OK)
	{
		displayModeName = (char *)malloc(32);
		snprintf(displayModeName, 32, "[index %d]", g_config.m_displayModeIndex);
	}

	// Check display mode is supported with given options
	result = g_deckLinkInput->DoesSupportVideoMode(displayMode->GetDisplayMode(), g_config.m_pixelFormat, bmdVideoInputFlagDefault, &displayModeSupported, NULL);
	if (result != S_OK)
		goto bail;

	if (displayModeSupported == bmdDisplayModeNotSupported)
	{
		fprintf(stderr, "The display mode %s is not supported with the selected pixel format\n", displayModeName);
		goto bail;
	}

	if (g_config.m_inputFlags & bmdVideoInputDualStream3D)
	{
		if (!(displayMode->GetFlags() & bmdDisplayModeSupports3D))
		{
			fprintf(stderr, "The display mode %s is not supported with 3D\n", displayModeName);
			goto bail;
		}
	}

	// Print the selected configuration
	g_config.DisplayConfiguration();

	// Configure the capture callback
	delegate = new DeckLinkCaptureDelegate();
	g_deckLinkInput->SetCallback(delegate);

	// Open output files
	if (g_config.m_videoOutputFile != NULL)
	{
		g_videoOutputFile = open(g_config.m_videoOutputFile, O_WRONLY|O_CREAT|O_TRUNC, 0664);
		if (g_videoOutputFile < 0)
		{
			fprintf(stderr, "Could not open video output file \"%s\"\n", g_config.m_videoOutputFile);
			goto bail;
		}
	}

	if (g_config.m_audioOutputFile != NULL)
	{
		g_audioOutputFile = open(g_config.m_audioOutputFile, O_WRONLY|O_CREAT|O_TRUNC, 0664);
		if (g_audioOutputFile < 0)
		{
			fprintf(stderr, "Could not open audio output file \"%s\"\n", g_config.m_audioOutputFile);
			goto bail;
		}
	}

	// Block main thread until signal occurs
	while (!g_do_exit)
	{
		// Start capturing
		result = g_deckLinkInput->EnableVideoInput(displayMode->GetDisplayMode(), g_config.m_pixelFormat, g_config.m_inputFlags);
		if (result != S_OK)
		{
			fprintf(stderr, "Failed to enable video input. Is another application using the card?\n");
			goto bail;
		}

		result = g_deckLinkInput->EnableAudioInput(bmdAudioSampleRate48kHz, g_config.m_audioSampleDepth, g_config.m_audioChannels);
		if (result != S_OK)
			goto bail;


    frameConsumer.Start();

		result = g_deckLinkInput->StartStreams();
		if (result != S_OK)
			goto bail;

		// All Okay.
		exitStatus = 0;

		pthread_mutex_lock(&g_sleepMutex);
		pthread_cond_wait(&g_sleepCond, &g_sleepMutex);
		pthread_mutex_unlock(&g_sleepMutex);

		fprintf(stderr, "Stopping Capture\n");
    frameConsumer.Stop();
		g_deckLinkInput->StopStreams();
		g_deckLinkInput->DisableAudioInput();
		g_deckLinkInput->DisableVideoInput();
	}

bail:

  delete g_lcm;

	if (g_videoOutputFile != 0)
		close(g_videoOutputFile);

	if (g_audioOutputFile != 0)
		close(g_audioOutputFile);

	if (displayModeName != NULL)
		free(displayModeName);

	if (displayMode != NULL)
		displayMode->Release();

	if (displayModeIterator != NULL)
		displayModeIterator->Release();

  if (conversionInst != NULL)
    conversionInst->Release();

	if (g_deckLinkInput != NULL)
	{
		g_deckLinkInput->Release();
		g_deckLinkInput = NULL;
	}

	if (g_deckLinkOutput != NULL)
	{
		g_deckLinkOutput->Release();
		g_deckLinkOutput = NULL;
	}

	if (deckLinkAttributes != NULL)
		deckLinkAttributes->Release();

	if (deckLink != NULL)
		deckLink->Release();

	if (deckLinkIterator != NULL)
		deckLinkIterator->Release();

	return exitStatus;
}
